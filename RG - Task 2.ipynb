{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Task 2 Webscraping\n",
        "### By Romina Goodarzi\n",
        "\n",
        "Please open this notebook on Google Colab."
      ],
      "metadata": {
        "id": "UMESdPY9rRXZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2J7CXLefrLSz"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "\n",
        "def scrape_list_page(url, site_name):\n",
        "    response = requests.get(url)\n",
        "    html_content = response.content\n",
        "    soup = BeautifulSoup(html_content, 'html.parser')\n",
        "\n",
        "    products = []\n",
        "    if site_name == 'missetam':\n",
        "        product_containers = soup.find_all('div', class_='product-item')\n",
        "        for i, container in enumerate(product_containers[:10]):\n",
        "            product = {'url': url, 'page_type': 'list', 'position': i+1}\n",
        "            name_tag = container.find('a', class_='product-item-link')\n",
        "            price_tag = container.find('span', class_='price')\n",
        "            discount_tag = container.find('span', class_='old-price')\n",
        "            product['name'] = name_tag.text.strip() if name_tag else None\n",
        "            product['price'] = price_tag.text.strip() if price_tag else None\n",
        "            product['discounted_price'] = discount_tag.text.strip() if discount_tag else None\n",
        "            products.append(product)\n",
        "    elif site_name == 'gap':\n",
        "        product_containers = soup.find_all('div', class_='product-card')\n",
        "        for i, container in enumerate(product_containers[:10]):\n",
        "            product = {'url': url, 'page_type': 'list', 'position': i+1}\n",
        "            name_tag = container.find('a', class_='product-card__link')\n",
        "            price_tag = container.find('span', class_='product-card__price')\n",
        "            discount_tag = container.find('span', class_='product-card__old-price')\n",
        "            product['name'] = name_tag.text.strip() if name_tag else None\n",
        "            product['price'] = price_tag.text.strip() if price_tag else None\n",
        "            product['discounted_price'] = discount_tag.text.strip() if discount_tag else None\n",
        "            products.append(product)\n",
        "    elif site_name == 'your_look_for_less':\n",
        "        product_containers = soup.find_all('div', class_='sc-b18a510e-3 fBMEnw')\n",
        "        for i, container in enumerate(product_containers[:10]):\n",
        "            product = {'url': url, 'page_type': 'list', 'position': i+1}\n",
        "            name_tag = container.find('strong', class_='sc-fed992a6-0 eJZrEW sc-b18a510e-5 cbyClg')\n",
        "            price_container = container.find('div', class_='sc-7f1e497e-1 kPIifX')\n",
        "            if price_container:\n",
        "                sale_price_tag = price_container.find('span', class_='sc-49115527-0 bkKyDO')\n",
        "                regular_price_tag = price_container.find('span', class_='sc-49115527-0 bVjZVj')\n",
        "                product['price'] = sale_price_tag.text.replace('€\\xa0', '€ ') if sale_price_tag else None\n",
        "                product['discounted_price'] = regular_price_tag.text.replace('€\\xa0', '€ ') if regular_price_tag else None\n",
        "            product['name'] = name_tag.text if name_tag else None\n",
        "            products.append(product)\n",
        "    return products\n",
        "\n",
        "def scrape_product_page(url, site_name):\n",
        "    response = requests.get(url)\n",
        "    html_content = response.content\n",
        "    soup = BeautifulSoup(html_content, 'html.parser')\n",
        "\n",
        "    product = {'url': url, 'page_type': 'product'}\n",
        "    if site_name == 'missetam':\n",
        "        name_tag = soup.find('h1', class_='product-name')\n",
        "        price_tag = soup.find('span', class_='price')\n",
        "        discount_tag = soup.find('span', class_='old-price')\n",
        "        brand_tag = soup.find('div', class_='product-brand')\n",
        "        images = soup.find_all('img', class_='gallery-image')\n",
        "        color_container = soup.find('div', class_='product-colors')\n",
        "        desc_tag = soup.find('div', class_='product-description')\n",
        "\n",
        "        product['name'] = name_tag.text.strip() if name_tag else None\n",
        "        product['price'] = price_tag.text.strip() if price_tag else None\n",
        "        product['discounted_price'] = discount_tag.text.strip() if discount_tag else None\n",
        "        product['brand'] = brand_tag.text.strip() if brand_tag else None\n",
        "        product['number_of_photos'] = len(images)\n",
        "        product['number_of_colors'] = len(color_container.find_all('div')) if color_container else 0\n",
        "        product['description'] = desc_tag.text.strip() if desc_tag else None\n",
        "    elif site_name == 'gap':\n",
        "        name_tag = soup.find('h1', class_='pdp-title')\n",
        "        price_tag = soup.find('span', class_='pdp-price')\n",
        "        discount_tag = soup.find('span', class_='pdp-price-old')\n",
        "        brand_tag = soup.find('a', class_='pdp-brand')\n",
        "        images = soup.find_all('img', class_='pdp-thumbnail')\n",
        "        color_container = soup.find('ul', class_='pdp-color-options')\n",
        "        desc_tag = soup.find('div', class_='pdp-description')\n",
        "\n",
        "        product['name'] = name_tag.text.strip() if name_tag else None\n",
        "        product['price'] = price_tag.text.strip() if price_tag else None\n",
        "        product['discounted_price'] = discount_tag.text.strip() if discount_tag else None\n",
        "        product['brand'] = brand_tag.text.strip() if brand_tag else None\n",
        "        product['number_of_photos'] = len(images)\n",
        "        product['number_of_colors'] = len(color_container.find_all('li')) if color_container else 0\n",
        "        product['description'] = desc_tag.text.strip() if desc_tag else None\n",
        "    elif site_name == 'your_look_for_less':\n",
        "        name_tag = soup.find('h1', class_='sc-b18a510e-0')\n",
        "        price_tag = soup.find('span', class_='sc-7f1e497e-2')\n",
        "        discount_tag = soup.find('span', class_='sc-49115527-0')\n",
        "        brand_tag = soup.find('div', class_='sc-298c6716-0')\n",
        "        images = soup.find_all('img', class_='sc-b9c7e565-0')\n",
        "        color_container = soup.find('div', class_='sc-375b6dc6-0')\n",
        "        desc_tag = soup.find('div', class_='sc-7f1e497e-4')\n",
        "\n",
        "        product['name'] = name_tag.text.strip() if name_tag else None\n",
        "        product['price'] = price_tag.text.strip() if price_tag else None\n",
        "        product['discounted_price'] = discount_tag.text.strip() if discount_tag else None\n",
        "        product['brand'] = brand_tag.text.strip() if brand_tag else None\n",
        "        product['number_of_photos'] = len(images)\n",
        "        product['number_of_colors'] = len(color_container.find_all('div')) if color_container else 0\n",
        "        product['description'] = desc_tag.text.strip() if desc_tag else None\n",
        "\n",
        "    return product\n",
        "\n",
        "def main():\n",
        "    list_pages = {\n",
        "        'missetam': \"https://www.missetam.nl/nl/collectie/jurken/\",\n",
        "        'gap': \"https://www.gap.com/browse/category.do?cid=5664&nav=meganav%3AWomen%3ACategor\",\n",
        "        'your_look_for_less': \"https://www.your-look-for-less.nl/goedkope-blouses\"\n",
        "    }\n",
        "\n",
        "    product_pages = {\n",
        "        'missetam': \"https://www.missetam.nl/nl/3844173/top-print-zwart/\",\n",
        "        'gap': \"https://www.gap.com/browse/product.do?pid=794603002&rrec=true&mlink=5001,1,dynami\",\n",
        "        'your_look_for_less': \"https://www.your-look-for-less.nl/p/99055\"\n",
        "    }\n",
        "\n",
        "    all_products = []\n",
        "\n",
        "    for site_name, url in list_pages.items():\n",
        "        products = scrape_list_page(url, site_name)\n",
        "        all_products.extend(products)\n",
        "\n",
        "    for site_name, url in product_pages.items():\n",
        "        product = scrape_product_page(url, site_name)\n",
        "        all_products.append(product)\n",
        "\n",
        "    with open('products.csv', 'w', newline='') as csvfile:\n",
        "        fieldnames = ['url', 'page_type', 'name', 'brand', 'price', 'discounted_price', 'position', 'number_of_photos', 'number_of_colors', 'description']\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "\n",
        "        writer.writeheader()\n",
        "        for product in all_products:\n",
        "            writer.writerow(product)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9DYsTC2rLSx",
        "outputId": "42fba523-0d24-4329-f2f8-f1a5324217fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.2.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "pip install requests beautifulsoup4 pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Thank You!\n",
        "I enjoy feedback - if you found something interesting, found an error, or have any comments, please let me know."
      ],
      "metadata": {
        "id": "ozbmmObJr8Ga"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}